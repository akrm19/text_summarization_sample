{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set env var OPENAI_API_KEY or load from a .env file\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "my_test = os.getenv(\"LANGSMITH_TRACING\")\n",
    "print(my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/troubleshooting/errors/', 'title': 'Troubleshooting', 'description': 'Build language agents as graphs', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTroubleshooting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n              Troubleshooting\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n    \\n  \\n  Home\\n\\n        \\n\\n\\n\\n          \\n  \\n    \\n  \\n  API reference\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Home\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n  \\n    Home\\n  \\n\\n          \\n\\n\\n\\n\\n\\n    \\n  \\n    Get started\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    Get started\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    Learn the basics\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Deployment\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Guides\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    Guides\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    How-to Guides\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Concepts\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Tutorials\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Resources\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n            \\n  \\n    Resources\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    Prebuilt Agents\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    Adopters\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    FAQ\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    Troubleshooting\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n  \\n    Troubleshooting\\n  \\n\\n          \\n\\n\\n\\n\\n    \\n  \\n    GRAPH_RECURSION_LIMIT\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    INVALID_CONCURRENT_GRAPH_UPDATE\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    INVALID_GRAPH_NODE_RETURN_VALUE\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    MULTIPLE_SUBGRAPHS\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    INVALID_CHAT_HISTORY\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n    \\n  \\n    INVALID_LICENSE\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    LangGraph Academy Course\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n  \\n    API reference\\n  \\n\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      \\n        LangGraph Platform\\n      \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Home\\n  \\n\\n\\n\\n\\n\\n    Resources\\n  \\n\\n\\n\\n\\n\\n    Troubleshooting\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nError reference¶\\nThis page contains guides around resolving common errors you may find while building with LangGraph.\\nErrors referenced below will have an lc_error_code property corresponding to one of the below codes when they are thrown in code.\\n\\nGRAPH_RECURSION_LIMIT\\nINVALID_CONCURRENT_GRAPH_UPDATE\\nINVALID_GRAPH_NODE_RETURN_VALUE\\nMULTIPLE_SUBGRAPHS\\nINVALID_CHAT_HISTORY\\n\\nLangGraph Platform¶\\nThese guides provide troubleshooting information for errors that are specific to the LangGraph Platform.\\n\\nINVALID_LICENSE\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Troubleshooting\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                GRAPH_RECURSION_LIMIT\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs Insiders\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "doc_url = \"https://langchain-ai.github.io/langgraph/troubleshooting/errors/\" #\"https://python.langchain.com/docs/contributing/\" #\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "loader = WebBaseLoader(doc_url)\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize in a single LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.llm import  LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\n\\n{context}\")]\n",
    ")\n",
    "\n",
    "# Instantiate chain\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Invoke chain\n",
    "result = chain.invoke({\"context\": docs})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"context\": docs}):\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map-Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "map_prompt = hub.pull(\"rlm/map-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also available via the hub: `hub.pull(\"rlm/reduce-prompt\")`\n",
    "reduce_template = \"\"\"\n",
    "The following is a set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary\n",
    "of the main themes.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 3 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "print(f\"generated {len(split_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoke chain\n",
    "result = chain.invoke({\"context\": [split_docs[0]]})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"context\": split_docs}):\n",
    "    print(token, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_summarization_sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
